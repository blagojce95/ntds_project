{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensRecommenderSystem():\n",
    "    \n",
    "    \n",
    "    def read_data(self, path):\n",
    "        data = pd.read_csv(path, delimiter = '\\t', header = None).rename(columns = {0: 'user', 1: 'movie', 2: 'rating'})\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def __init__(self, train_data_path, seed = 17):\n",
    "        # Set parameters\n",
    "        self.DATA_DIR = 'ml-100k/'\n",
    "        self.train_data_path = train_data_path\n",
    "        self.seed = seed\n",
    "        \n",
    "        # Read the training data\n",
    "        self.train_df = self.read_data(os.path.join(self.DATA_DIR, self.train_data_path))\n",
    "        \n",
    "        # Find list of unique user IDs\n",
    "        self.inv_map_users = list(set(self.train_df['user']))\n",
    "        self.num_users = len(self.inv_map_users)\n",
    "\n",
    "        # Find lsit of unique movie IDs\n",
    "        self.inv_map_movies = list(set(self.train_df['movie']))\n",
    "        self.num_movies = len(self.inv_map_movies)\n",
    "        \n",
    "        # Find mapping of the original user ID to [0, N - 1]\n",
    "        self.map_users = {x: i for i, x in enumerate(self.inv_map_users)}\n",
    "        self.map_movies = {x: i for i, x in enumerate(self.inv_map_movies)}\n",
    "        \n",
    "        # Apply the mapping on the actual data\n",
    "        self.train_df['user'] = self.train_df['user'].apply(lambda x: self.map_users[x])\n",
    "        self.train_df['movie'] = self.train_df['movie'].apply(lambda x: self.map_movies[x])\n",
    "        \n",
    "    \n",
    "    def predict(self, P, Q, u, i):\n",
    "        # Predict the rating of user u and movie i\n",
    "        return P[u].dot(Q[i])\n",
    "    \n",
    "    \n",
    "    def cross_validate(self, n_splits = 5, K = 50, learning_rate = .01, regularization_rate = .017, bias = True, max_it = 500, seed = 17):\n",
    "        # Initialize KFold object\n",
    "        kf = KFold(n_splits = 5, random_state = seed, shuffle = True)\n",
    "        \n",
    "        # Evaluate RMSE for every fold\n",
    "        total_error = 0\n",
    "        for it, (train_idx, val_idx) in enumerate(kf.split(self.train_df)):\n",
    "            # Get the train / validation data\n",
    "            train_data = self.train_df.loc[train_idx]\n",
    "            val_data = self.train_df.loc[val_idx]\n",
    "            \n",
    "            # Get the RMSE for the it-th fold\n",
    "            print('Fold: %d/%d' % (it + 1, n_splits))\n",
    "            cur_error = self.evaluate_matrix_factorization(train_data, val_data, K = K, learning_rate = learning_rate, bias = bias,\n",
    "                                                           regularization_rate = regularization_rate, max_it = max_it, seed = seed)\n",
    "            print()\n",
    "            \n",
    "            # Get the total error (squared errors)\n",
    "            total_error += np.power(cur_error, 2) * len(val_data)\n",
    "        \n",
    "        # Calculate the total RMSE for all n-folds (weighted, useful if the validation datasets have different sizes)\n",
    "        final_error = np.power(total_error / len(self.train_df), 1 / 2)\n",
    "        print('Error: %.5f' % final_error)\n",
    "    \n",
    "        \n",
    "    def evaluate_matrix_factorization(self, train_data, val_data, K = 50, learning_rate = .01, regularization_rate = .017, bias = True, max_it = 500, seed = 17):\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Latent space dimension\n",
    "        dim = K + (2 if bias else 0)\n",
    "        \n",
    "        # Initialize matrices P, Q ... the embeddings of the user and movies\n",
    "        P = np.random.choice([-0.01, 0.01], size = self.num_users * dim).reshape((self.num_users, dim))\n",
    "        Q = np.random.choice([-0.01, 0.01], size = self.num_movies * dim).reshape((self.num_movies, dim))\n",
    "        \n",
    "        # Initialize one column to be 1 so that we can learn the bias\n",
    "        if bias:\n",
    "            P[:, K] = 1\n",
    "            Q[:, K + 1] = 1\n",
    "        \n",
    "        # Perform SGD on P, Q until RMSE on the validation dataset increases\n",
    "        error = 1e9\n",
    "        for it in range(max_it):\n",
    "            # For every entry in the training data\n",
    "            for u, i, r in zip(train_data['user'], train_data['movie'], train_data['rating']):\n",
    "                # Get the prediction, and error\n",
    "                r_pred = self.predict(P, Q, u, i)\n",
    "                e_ui = r - r_pred\n",
    "                \n",
    "                # Find the updates for the approriate rows in P and Q\n",
    "                nP_u = P[u] + learning_rate * (e_ui * Q[i] - regularization_rate * P[u])\n",
    "                nQ_i = Q[i] + learning_rate * (e_ui * P[u] - regularization_rate * Q[i])\n",
    "                \n",
    "                # Set the approriate element to be 1 for the bias\n",
    "                if bias:\n",
    "                    nP_u[K] = 1\n",
    "                    nQ_i[K + 1] = 1\n",
    "\n",
    "                # Update the matrices\n",
    "                P[u] = nP_u\n",
    "                Q[i] = nQ_i\n",
    "            \n",
    "            # Calculate RMSE on the validation dataset\n",
    "            cur_error = 0\n",
    "            for u, i, r in zip(val_data['user'], val_data['movie'], val_data['rating']):\n",
    "                # Get the prediction, and error\n",
    "                r_pred = self.predict(P, Q, u, i)\n",
    "                e_ui = r - r_pred\n",
    "                \n",
    "                # Error squared\n",
    "                cur_error += np.power(e_ui, 2)\n",
    "            # Final RMSE\n",
    "            cur_error = np.power(cur_error / len(val_data), 1 / 2)\n",
    "            \n",
    "            # print('%3d\\t%.5f' % (it, cur_error))\n",
    "            \n",
    "            # If RMSE on validation dataset increases, stop the learning\n",
    "            if cur_error >= error:\n",
    "                break\n",
    "            error = cur_error\n",
    "        \n",
    "        print('-------------------')\n",
    "        print('%3d\\t%.5f' % (it, cur_error))\n",
    "        \n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MovieLensRecommenderSystem('u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1/5\n",
      "-------------------\n",
      " 34\t0.90407\n",
      "\n",
      "Fold: 2/5\n",
      "-------------------\n",
      " 34\t0.90705\n",
      "\n",
      "Fold: 3/5\n",
      "-------------------\n",
      " 33\t0.90589\n",
      "\n",
      "Fold: 4/5\n",
      "-------------------\n",
      " 34\t0.91258\n",
      "\n",
      "Fold: 5/5\n",
      "-------------------\n",
      " 34\t0.90136\n",
      "\n",
      "Error: 0.90614\n"
     ]
    }
   ],
   "source": [
    "x.cross_validate(learning_rate = .01, regularization_rate = .051, bias = True, seed = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
